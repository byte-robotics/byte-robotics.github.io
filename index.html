<html><head>
<title>Tao Kong</title>

<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">

<script src="https://code.jquery.com/jquery-3.1.1.slim.min.js" integrity="sha384-A7FZj7v+d/sdmMqp/nOQwliLvUsJfDHW+k9Omg/a/EheAdgtzNs3hpfag6Ed950n" crossorigin="anonymous"></script>

<style type="text/css">
 @import url("http://fonts.googleapis.com/css?family=Source+Sans+Pro:300,300italic,600,600italic");


	body
	{
	font-family:"Roboto",Helvetica,Arial,sans-serif;font-size:16px;line-height:1.5;font-weight:300;
    	background-color : #CDCDCD;
	}
    	.content
	{
    		width : 900px;
    		padding : 25px 30px;
    		margin : 25px auto;
    		background-color : #fff;
    		box-shadow: 0px 0px 10px #999;
    		border-radius: 15px; 
	}	
	table
	{
		padding: 5px;
	}
	
	table.pub_table,td.pub_td1,td.pub_td2
	{
		padding: 8px;
		width: 850px;
        border-collapse: separate;
        border-spacing: 15px;
        margin-top: -5px;
	}

	td.pub_td1
	{
		width:50px;
	}
    td.pub_td1 img
    {
        height:120px;
        width: 160px;
    }
	
	div#container
	{
		margin-left: auto;
		margin-right: auto;
		width: 820px;
		text-align: left;
		position: relative;
		background-color: #FFF;
	}
	div#DocInfo
	{
		color: #1367a7;
		height: 158px;
		margin-left: 20px;
	}
	h4,h3,h2,h1
	{
		color: #3B3B3B;
	}
	h2
	{
		font-size:130%;
	}
	p
	{
		color: #5B5B5B;
		margin-bottom: 50px;
	}
	p.caption
	{
		color: #9B9B9B;
		text-align: left;
		width: 600px;
	}
	p.caption2
	{
		color: #9B9B9B;
		text-align: left;
		width: 800px;
	}
	#header_img
	{
		position: absolute;
		top: 0px; right: 0px;
    }
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}

    #mit_logo {
        position: absolute;
        left: 646px;
        top: 14px;
        width: 200px;
        height: 20px;
    }
   
    table.pub_table tr {
        outline: thin dotted #666666;
    }
    .papericon {
        border-radius: 8px; 
        -moz-box-shadow: 3px 3px 6px #888;
        -webkit-box-shadow: 3px 3px 6px #888;
        box-shadow: 3px 3px 6px #888;
        width: 180px;
	margin-top:5px;
	margin-left:5px;
	margin-bottom:5px;
    }

     .papericon_blank {

        width: 160px;
	margin-top:5px;
	margin-left:5px;
	margin-bottom:5px;
    }

    .media {
	outline: thin dotted #666666;
 	margin-bottom: 15px;	
	margin-left:10px;
    }
    .media-body {
	margin-top:5px;
	padding-left:20px;
    }
    .instructorphoto img {
	  width: 170px;
	  border-radius: 170px;
	  margin-bottom: 10px;
	}


.papers-selected h5, .papers-selected h4 { display : none; }
.papers-selected .publication { display : none; }
.paperhi-only { display : none; }
.papers-selected .paperhi { display : flex; }
.papers-selected .paperlo { display : none; }

.hidden>div {
	display:none;
}

.visible>div {
	display:block;
}
</style>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-23931362-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-23931362-2');
</script>

<script type="text/javascript">
    var myPix = new Array("profile.jpg")
    function choosePic() {
        var randomNum = Math.floor(Math.random() * myPix.length);
        document.getElementById("myPicture").src = myPix[randomNum];
    };
</script>

<script>
$(document).ready(function() {
  $('.paperlo button').click(function() {
     $('.papers-container').addClass('papers-selected');
  });
  $('.paperhi button').click(function() {
     $('.papers-container').removeClass('papers-selected');
  });


	$('.text_container').addClass("hidden");

	$('.text_container').click(function() {
		var $this = $(this);

		if ($this.hasClass("hidden")) {
			$(this).removeClass("hidden").addClass("visible");
			$(this).removeClass("papericon");
		} else {
			$(this).removeClass("visible").addClass("hidden");
		}
	});


});
</script>

</head>

<body>
<div class="content">
	<div id="container">

	<table>
	<tbody><tr>
	<td><div class="instructorphoto"><img id="myPicture" src="profile.jpg" style="float:left;"></div></td>
	<script>choosePic();</script>
	<td>
	<div id="DocInfo">
		<h1>Tao Kong</h1>
        Research Scientist<br>
	BytedDance AI Lab<br>
        Email: <a href="mailto:taokongcn@gmail.com">taokongcn@gmail.com</a><br>
        <a href="https://scholar.google.com/citations?user=kSUXLPkAAAAJ&hl=en">Google Scholar</a> &bull; 
		<a href="https://arxiv.org/find/cs/1/au:+Kong_Tao/0/1/0/all/0/1">arXiv</a> &bull; 
		<a href="https://github.com/taokong">Github</a> &bull; 
		<a href="https://www.zhihu.com/people/kong-tao-72">Zhihu</a><br>
	</div><br>
    <!--
    <div id="mit_logo">
        <a href="http://www.mit.edu"><img src="image/mit.gif" height="170px" class="papericon" /></a>
    </div>
    -->
	</td>
	</tr>
	</tbody></table>
	<br>
	

<h2>Biography</h2>
<p>
    Tao Kong is currently a research scientist at Bytedance AI Lab.
    Before that, he received Ph.D. degree of computer science in Tsinghua University, under the supervision of Prof. Fuchun Sun. 
<!--     His Ph.D dissertation was awarded Excellent Doctoral Dissertation Nomination Award of CAAI at 2020. -->
    From Oct 2018 to Mar 2019, he visited Grasp Lab in University of Pennsylvania, supervised by Prof. Jianbo Shi. 
    Previously, he co-founded a promising start-up company, which aimed at machine vision based industry products.
    He also interned at VC Group of MSRA and Cognitive Computing Lab of Intel.</p>
<p>We are recruiting self-motivated interns / full-time researchers and developers in vision / language understanding, and robotics learning. If you are interested, please drop me an email. </p> 
	
   
<!-- 
<h2>News</h2>	
    <ul>
        <li>[07/2020] <a href="https://arxiv.org/abs/1912.04488">SOLO</a> paper is accepted to <b>ECCV 2020</b>. </li>
        <li>[06/2020] <a href="https://arxiv.org/abs/1904.03797">FoveaBox</a> paper is accepted to <b>TIP</b>. </li>
        <li>[11/2019] <a href="https://arxiv.org/abs/1909.07701">FoveaBox</a> paper is accepted to <b>TIP</b>. </li>

    </ul> -->

	
<h2>Publications <small>(<a href="https://scholar.google.com/citations?user=kSUXLPkAAAAJ&hl=en">Google Scholar</a>)</small></h2>
<small>(* Interns, <sup>+</sup> Equal contribution)</small>
<ul> 
<li>
      <a href="https://arxiv.org/abs/2003.10152">SOLOv2: Dynamic and Fast Instance Segmentation</a><br>
	     Xinlong Wang*, Rufeng Zhang*, <b>Tao Kong</b>, Lei Li and Chunhua Shen<br>
                <em>Advances in Neural Information Processing Systems</em> (<b>NeurIPS</b>), 2020<br>
		[<a href="https://arxiv.org/abs/2003.10152">arXiv</a>][<a href="https://github.com/WXinlong/SOLO">Code@Github</a>]<img alt="GitHub stars" src="https://img.shields.io/github/stars/WXinlong/SOLO?label=Stars&style=social"><br>
      </li>

      <li>
      <a href="https://arxiv.org/abs/1912.04488">SOLO: Segmenting Objects by Locations</a><br>
	     Xinlong Wang*, <b>Tao Kong</b>, Chunhua Shen, Yuning Jiang and Lei Li<br>
                <em>European Conference on Computer Vision</em> (<b>ECCV</b>), 2020<br>
		[<a href="https://arxiv.org/abs/1912.04488">arXiv</a>][<a href="https://mp.weixin.qq.com/s/WAjIWSLgJLVE0KsJZdtqGA">QbitAI News</a>][<a href="https://github.com/WXinlong/SOLO">Code@Github</a>]<img alt="GitHub stars" src="https://img.shields.io/github/stars/WXinlong/SOLO?label=Stars&style=social"><br>
      </li>
	
      <li>
      <a href="https://arxiv.org/abs/1904.03797">FoveaBox: Beyond Anchor-based Object Detector</a><br>
	     <b>Tao Kong</b>, Fuchun Sun, Huaping Liu, Yuning Jiang, Lei Li, Jianbo Shi<br>
                <em>IEEE Transactions on Image Processing</em> (<b>TIP</b>), 2020<br>
		[<a href="https://arxiv.org/abs/1904.03797">arXiv</a>][<a href="https://www.jiqizhixin.com/articles/2019-05-05-10">Synced News</a>][<a href="https://github.com/open-mmlab/mmdetection/tree/master/configs/foveabox">Code@mmdet</a>][<a href="https://github.com/taokong/FoveaBox">Code@Github</a>]<img alt="GitHub stars" src="https://img.shields.io/github/stars/taokong/FoveaBox?label=Stars&style=social"><br>
      </li>
	      
      <li>
      <a href="https://arxiv.org/abs/1909.07701">Task-Aware Monocular Depth Estimation for 3D Object Detection
</a><br>
	     Xinlong Wang*, Wei Yin, <b>Tao Kong</b>, Yuning Jiang, Lei Li and Chunhua Shen<br>
                AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2020 (<font color="red">Oral</font>)<br>
		[<a href="https://arxiv.org/abs/1909.07701">arXiv</a>][<a href="https://github.com/WXinlong/ForeSeE">Code@Github</a>]<img alt="GitHub stars" src="https://img.shields.io/github/stars/WXinlong/ForeSeE?label=Stars&style=social"><br>
      </li>
 
	
    <li>
      <a href="https://ieeexplore.ieee.org/document/8721661/authors#authors">Feature Pyramid Reconfiguration with Consistent Loss for Object Detection
</a>,<br>
	     <b>Tao Kong</b><sup>+</sup>, Fuchun Sun<sup>+</sup>,  Wenbing Huang, Chuanqi Tan, Bin Fang, Huaping Liu<br>
                <em>IEEE Transactions on Image Processing</em> (<b>TIP</b>), 2019<br>
    </li>
	
	<li>
      <a href="https://arxiv.org/abs/1812.01210">Zoom-In-to-Check: Boosting Video Interpolation via Instance-level Discrimination
</a><br>
	     Liangzhe Yuan<sup>+</sup>, Yibo Chen<sup>+</sup>, Hantian Liu, <b>Tao Kong</b>, Jianbo Shi<br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2019<br>
		[<a href="https://arxiv.org/abs/1812.01210">arXiv</a>][<a href="https://youtu.be/q-_wIRq26DY">demo</a>]<br>
    </li>
	

     <li>
      <a href="https://arxiv.org/abs/1808.07993">Deep Feature Pyramid Reconfiguration for Object Detection</a><br>
        <b>Tao Kong</b>, Fuchun Sun, Chuanqi Tan, Huaping Liu, Wenbing Huang<br>
                <em>European Conference on Computer Vision</em> (<b>ECCV</b>), 2018<br>
		[<a href="https://arxiv.org/abs/1808.07993">arXiv</a>][<a href="https://taokong.github.io/papers/eccv2018_kong_poster.pdf">poster</a>]<br>
    </li>

     <li>
      <a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Kong_RON_Reverse_Connection_CVPR_2017_paper.pdf">RON: Reverse Connection with Objectness Prior Networks for Object Detection</a><br>
        <b>Tao Kong</b>, Fuchun Sun, Anbang Yao, Huaping Liu, Yurong Chen, Ming Lu<br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2017<br>
	     	[<a href="https://arxiv.org/abs/1707.01691">arXiv</a>][<a href="http://www.sohu.com/a/156480214_473283">Sohu News</a>][<a href="https://github.com/taokong/RON">Code@Github</a>]<img alt="GitHub stars" src="https://img.shields.io/github/stars/taokong/RON?label=Stars&style=social"><br>
    </li>
	
    <li>
      <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Kong_HyperNet_Towards_Accurate_CVPR_2016_paper.pdf">HyperNet: Towards Accurate Region Proposal Generation and Joint Object Detection</a><br>
        <b>Tao Kong</b>, Anbang Yao, Yurong Chen, Fuchun Sun<br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2016 (<font color="red">Spotlight</font>) <br>
    </li>

    <li>
      <a href="http://ieeexplore.ieee.org/document/7487351/?tp=&arnumber=7487351&url=http:%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D7487351">
      Object Discovery and Grasp Detection with A Shared Convolutional Neural Network<br></a>
        Di Guo, <b>Tao Kong</b>, Fuchun Sun, Huaping Liu<br>
            <em> IEEE International Conference on Robotics and Automation</em> (<b>ICRA</b>), 2016 (<font color="red">Oral</font>)  <br>
	    <a href="https://news.tsinghua.edu.cn/info/1003/23128.htm">The 1st place of 2016 IROS Robotic Grasping and Manipulation Competition!</a><br>
    </li>

	
		
      <li>
      <a href="https://journals.sagepub.com/doi/full/10.1177/1729881416682706">Deep Vision Networks for Real-time Robotic Grasp Detection

</a>,<br>
	     Di Guo, Fuchun Sun, <b>Tao Kong</b>, Huaping Liu<br>
                <em>International Journal of Advanced Robotic Systems</em> (<b>IJARS</b>), 2016<br>
    </li>
	
      <li>
      <a href="https://link.springer.com/article/10.1186/1687-6180-2014-44">A Hierarchical Classification Method for Finger Knuckle Print Recognition</a><br>
	     <b>Tao Kong</b>, Gongping Yang, Lu Yang<br>
                <em>EURASIP Journal on Advances in Signal Processing</em>, 2014<br>
      </li>
	
      <li>
      <a href="https://link.springer.com/article/10.1186/1687-6180-2014-44">A New Finger-knuckle-print ROI Extraction Method Based on Probabilistic Region Growing Algorithm
</a><br>
	     <b>Tao Kong</b>, Gongping Yang, Lu Yang<br>
                <em>International Journal of Machine Learning and Cybernetics</em>, 2014<br>
      </li>

	
</ul> 

<h2>Honors & Awards</h2>
<ul> 
    <li>
    <a href="papers/CAAI-Tao.pdf">CAAI Excellent Doctoral Dissertation Nomination Award</a>, 2020
    </li>
    <li>
    CSC Scholarship, 2018
    </li>
    <li>
    The 1st place of IROS Robotic Grasping and Manipulation Competition, 2016
    </li>
    <li>
    Intel Division Recognition Award, 2016
    </li>
    <li>
    Outstanding Graduates in Shandong Province and Shandong University, 2014
    </li>
    <li>
    CCF Outstanding Undergraduate Award, 2013
    </li>
    <li>
    IBM Excellence Scholarship, 2013
    </li>
    <li>
    Young Science Award of Shandong University, 2013
    </li>
    <li>
    National Scholarship, 2012-2013
    </li>
</ul>
	


<!-- <h2>Academic Service</h2>
<ul>    
    <li>
    Conference Reviewer: CVPR, ICCV, ECCV, NeurIPS, ICLR, etc.
    </li>
    <li>
    Journal Reviewer: TPAMI, TIP, PR, etc.
    </li>
</ul> -->


<p>　</p>
<p>　</p>
<a href="http://www.easycounter.com/">
<img src="//www.easycounter.com/counter.php?taokongcn"
border="0" alt="Free Hit Counters"></a>
<br><a href="http://www.easycounter.com/">visitors
        since May 2016</a>

<p align="left"><i>Last update: Oct, 2020</i> </p>


</body></html>
