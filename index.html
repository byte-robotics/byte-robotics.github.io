<html><head>
<title>Tao Kong</title>

<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">

<script src="https://code.jquery.com/jquery-3.1.1.slim.min.js" integrity="sha384-A7FZj7v+d/sdmMqp/nOQwliLvUsJfDHW+k9Omg/a/EheAdgtzNs3hpfag6Ed950n" crossorigin="anonymous"></script>

<style type="text/css">
 @import url("http://fonts.googleapis.com/css?family=Source+Sans+Pro:300,300italic,600,600italic");


	body
	{
	font-family:"Roboto",Helvetica,Arial,sans-serif;font-size:16px;line-height:1.5;font-weight:300;
    	background-color : #CDCDCD;
	}
    	.content
	{
    		width : 900px;
    		padding : 25px 30px;
    		margin : 25px auto;
    		background-color : #fff;
    		box-shadow: 0px 0px 10px #999;
    		border-radius: 15px; 
	}	
	table
	{
		padding: 5px;
	}
	
	table.pub_table,td.pub_td1,td.pub_td2
	{
		padding: 8px;
		width: 850px;
        border-collapse: separate;
        border-spacing: 15px;
        margin-top: -5px;
	}

	td.pub_td1
	{
		width:50px;
	}
    td.pub_td1 img
    {
        height:120px;
        width: 160px;
    }
	
	div#container
	{
		margin-left: auto;
		margin-right: auto;
		width: 820px;
		text-align: left;
		position: relative;
		background-color: #FFF;
	}
	div#DocInfo
	{
		color: #1367a7;
		height: 158px;
		margin-left: 20px;
	}
	h4,h3,h2,h1
	{
		color: #3B3B3B;
	}
	h2
	{
		font-size:130%;
	}
	p
	{
		color: #5B5B5B;
		margin-bottom: 50px;
	}
	p.caption
	{
		color: #9B9B9B;
		text-align: left;
		width: 600px;
	}
	p.caption2
	{
		color: #9B9B9B;
		text-align: left;
		width: 800px;
	}
	#header_img
	{
		position: absolute;
		top: 0px; right: 0px;
    }
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}

    #mit_logo {
        position: absolute;
        left: 646px;
        top: 14px;
        width: 200px;
        height: 20px;
    }
   
    table.pub_table tr {
        outline: thin dotted #666666;
    }
    .papericon {
        border-radius: 8px; 
        -moz-box-shadow: 3px 3px 6px #888;
        -webkit-box-shadow: 3px 3px 6px #888;
        box-shadow: 3px 3px 6px #888;
        width: 180px;
	margin-top:5px;
	margin-left:5px;
	margin-bottom:5px;
    }

     .papericon_blank {

        width: 160px;
	margin-top:5px;
	margin-left:5px;
	margin-bottom:5px;
    }

    .media {
	outline: thin dotted #666666;
 	margin-bottom: 15px;	
	margin-left:10px;
    }
    .media-body {
	margin-top:5px;
	padding-left:20px;
    }
    .instructorphoto img {
	  width: 170px;
	  border-radius: 170px;
	  margin-bottom: 10px;
	}


.papers-selected h5, .papers-selected h4 { display : none; }
.papers-selected .publication { display : none; }
.paperhi-only { display : none; }
.papers-selected .paperhi { display : flex; }
.papers-selected .paperlo { display : none; }

.hidden>div {
	display:none;
}

.visible>div {
	display:block;
}
</style>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-23931362-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-23931362-2');
</script>

<script type="text/javascript">
    var myPix = new Array("profile.jpg")
    function choosePic() {
        var randomNum = Math.floor(Math.random() * myPix.length);
        document.getElementById("myPicture").src = myPix[randomNum];
    };
</script>

<script>
$(document).ready(function() {
  $('.paperlo button').click(function() {
     $('.papers-container').addClass('papers-selected');
  });
  $('.paperhi button').click(function() {
     $('.papers-container').removeClass('papers-selected');
  });


	$('.text_container').addClass("hidden");

	$('.text_container').click(function() {
		var $this = $(this);

		if ($this.hasClass("hidden")) {
			$(this).removeClass("hidden").addClass("visible");
			$(this).removeClass("papericon");
		} else {
			$(this).removeClass("visible").addClass("hidden");
		}
	});


});
</script>

</head>

<body>
<div class="content">
	<div id="container">

	<table>
	<tbody><tr>
	<td><div class="instructorphoto"><img id="myPicture" src="profile.jpg" style="float:left;"></div></td>
	<script>choosePic();</script>
	<td>
	<div id="DocInfo">
		<h1>Tao Kong</h1><br>
        ByteDance AI Lab<br><br>
        Email: <a href="mailto:taokongcn@gmail.com">taokongcn@gmail.com</a><br><br>
        <a href="https://scholar.google.com/citations?user=kSUXLPkAAAAJ&hl=en">Google Scholar</a> &bull; 
		<a href="https://arxiv.org/find/cs/1/au:+Kong_Tao/0/1/0/all/0/1">arXiv</a> &bull; 
		<a href="https://github.com/taokong">Github</a> &bull; 
		<a href="https://www.zhihu.com/people/kong-tao-72">Zhihu</a><br>
	</div><br>
    <!--
    <div id="mit_logo">
        <a href="http://www.mit.edu"><img src="image/mit.gif" height="170px" class="papericon" /></a>
    </div>
    -->
	</td>
	</tr>
	</tbody></table>
	<br>
	

<h2>Intro</h2>
<ul>
<li>I am currently a research scientist at ByteDance AI Lab, working closely with Dr. <a href="https://lileicc.github.io">Lei Li</a>.</li>
<li>I received Ph.D. degree from Tsinghua University under the supervision of Prof. <a href="https://scholar.google.com/citations?user=DbviELoAAAAJ&hl=en">Fuchun Sun</a>. 
    From 2018 to 2019, I visited GRASP Lab of University of Pennsylvania, working with Prof. <a href="https://www.cis.upenn.edu/~jshi">Jianbo Shi</a>. </li>
<li>During my Ph.D. study, I did a long-term and happy internship in Intel Labs mentored by Dr. <a href="https://yaoanbang.github.io/">Anbang Yao</a>. 
	Before graduation, I also spent time at MSRA working with Dr. <a href="https://jifengdai.org">Jifeng Dai</a> and Dr. <a href="https://ancientmooner.github.io">Han Hu</a>.</li>
<li><a href="https://zhuanlan.zhihu.com/p/348800405">We are recruiting self-motivated interns / full-time researchers and developers in robotics learning.</a></li>
	
</ul> 

<h2>News</h2>	
    <ul>
        <li>[07/2021] Two papers are accepted to <a href="https://www.iros2021.org">IROS 2021</a>. </li>
	<li>[03/2021] Four papers are accepted to <a href="http://cvpr2021.thecvf.com">CVPR 2021</a>, and DenseCL is selected as the Oral presentation! </li>
	<li>[01/2021] Organizing a tutorial <a href="https://www.2021.ieeeicip.org">Recent Progress on Visual Object Detection and Segmentation</a> at ICIP 2021. </li>    
        <li>[10/2020] My thesis is nominated as the <a href="papers/CAAI-Tao.pdf">CAAI Excellent Doctoral Dissertation Award</a>. </li>    
	<li>[09/2020] Our <a href="https://arxiv.org/abs/2003.10152">SOLOv2</a> work is accepted to NeurIPS 2020. </li>    
        <li>[07/2020] Our <a href="https://arxiv.org/abs/1912.04488">SOLO</a> work is accepted to ECCV 2020. </li>
        <li>[06/2020] Our <a href="https://arxiv.org/abs/1904.03797">FoveaBox</a> work is accepted to TIP 2020. </li>

    </ul>

	
<h2>Selected Publications</h2>

<ul> 
	<li>
      <b>Learning to Design and Construct Bridge without Blueprint</b><br>
	     Yunfei Li, Tao Kong, Lei Li, Yifeng Li and Yi Wu<br>
             IROS 2021. <br>
      </li>
	
      <li>
      <b>Simultaneous Semantic and Collision Learning for 6-DoF Grasp Pose Estimation</b><br>
	     Yiming Li, Tao Kong, Ruihang Chu, Yifeng Li, Peng Wang and Lei Li<br>
             IROS 2021. <br>
      </li>
      <li>
      <b>Scale-aware Automatic Augmentation for Object Detection</b><br>
	     Yukang Chen, Yanwei Li, Tao Kong, Lu Qi, Ruihang Chu, Lei Li and Jiaya Jia<br>
             CVPR 2021. [<a href="https://arxiv.org">Paper</a>][<a href="https://github.com/Jia-Research-Lab/SA-AutoAug">Code</a>]<img alt="GitHub stars" src="https://img.shields.io/github/stars/Jia-Research-Lab/SA-AutoAug?label=Stars&style=social"><br>
      </li>
	
      <li>
      <b>Locate then Segment: A Strong Pipeline for Referring Image Segmentation</b><br>
	     Ya Jing, Tao Kong, Wei Wang, Liang Wang, Lei Li and Tieniu Tan<br>
             CVPR 2021. [<a href="https://arxiv.org">Paper</a>]<br>
      </li>
	
      <li>
      <b>Dense Contrastive Learning for Self-Supervised Visual Pre-Training</b><br>
	     Xinlong Wang, Rufeng Zhang, Chunhua Shen, Tao Kong and Lei Li<br>
             CVPR 2021, Oral. [<a href="https://arxiv.org/abs/2011.09157">Paper</a>][<a href="https://github.com/WXinlong/DenseCL">Code</a>]<img alt="GitHub stars" src="https://img.shields.io/github/stars/WXinlong/DenseCL?label=Stars&style=social"><br>
      </li>
      
      <li>
      <b>Sparse R-CNN: End-to-End Object Detection with Learnable Proposals</b><br>
	Peize Sun, Rufeng Zhang, Yi Jiang, Tao Kong, Chenfeng Xu, Wei Zhan, Masayoshi Tomizuka, Lei Li, Zehuan Yuan, Changhu Wang, Ping Luo<br>
             CVPR 2021. [<a href="https://arxiv.org/abs/2011.12450">Paper</a>][<a href="https://github.com/PeizeSun/SparseR-CNN">Code</a>]<img alt="GitHub stars" src="https://img.shields.io/github/stars/PeizeSun/SparseR-CNN?label=Stars&style=social"><br>
      </li>
	
	
      <li>
      <b>SOLOv2: Dynamic and Fast Instance Segmentation</b><br>
	     Xinlong Wang, Rufeng Zhang, Tao Kong, Lei Li and Chunhua Shen<br>
             NeurIPS 2020. [<a href="https://arxiv.org/abs/2003.10152">Paper</a>][<a href="https://github.com/WXinlong/SOLO">Code</a>]<img alt="GitHub stars" src="https://img.shields.io/github/stars/WXinlong/SOLO?label=Stars&style=social"><br>
	     &#128515;<a href="https://www.topbots.com/neurips-2020-vision-research-papers"><font color="#800000"><b>NeurIPS 2020 Top 10 Key Research Papers in Computer Vision</b></font></a><br>
      </li>

      <li>
      <b>SOLO: Segmenting Objects by Locations</b><br>
	     Xinlong Wang, Tao Kong, Chunhua Shen, Yuning Jiang and Lei Li<br>
             ECCV 2020. [<a href="projects/solo">Project Page</a>][<a href="https://arxiv.org/abs/1912.04488">Paper</a>][<a href="https://github.com/WXinlong/SOLO">Code</a>]<img alt="GitHub stars" src="https://img.shields.io/github/stars/WXinlong/SOLO?label=Stars&style=social"><br>
      </li>
	
      <li>
      <b>FoveaBox: Beyond Anchor-based Object Detector</b><br>
	     Tao Kong, Fuchun Sun, Huaping Liu, Yuning Jiang, Lei Li, Jianbo Shi<br>
             TIP 2020. [<a href="projects/FoveaBox">Project Page</a>][<a href="https://arxiv.org/abs/1904.03797">Paper</a>][<a href="https://github.com/taokong/FoveaBox">Code</a>]<img alt="GitHub stars" src="https://img.shields.io/github/stars/taokong/FoveaBox?label=Stars&style=social"><br>
	     &#128515;<font color="#800000"><b>ESI Highly Cited Paper (Top 1%)</b></font><br>

	</li>
	      
      <li>
      <b>Task-Aware Monocular Depth Estimation for 3D Object Detection</b><br>
	     Xinlong Wang, Wei Yin, Tao Kong, Yuning Jiang, Lei Li and Chunhua Shen<br>
             AAAI 2020, Oral. [<a href="https://arxiv.org/abs/1909.07701">Paper</a>][<a href="https://github.com/WXinlong/ForeSeE">Code</a>]<img alt="GitHub stars" src="https://img.shields.io/github/stars/WXinlong/ForeSeE?label=Stars&style=social"><br>
      </li>
 
	
    <li>
      <b>Feature Pyramid Reconfiguration with Consistent Loss for Object Detection</b><br>
	     Tao Kong, Fuchun Sun,  Wenbing Huang, Chuanqi Tan, Bin Fang, Huaping Liu<br>
             TIP 2019. [<a href="https://ieeexplore.ieee.org/document/8721661/authors#authors">Paper</a>]<br>
    </li>
	
	<li>
      <b>Zoom-In-to-Check: Boosting Video Interpolation via Instance-level Discrimination</b><br>
	     Liangzhe Yuan, Yibo Chen, Hantian Liu, Tao Kong, Jianbo Shi<br>
             CVPR 2019. [<a href="https://arxiv.org/abs/1812.01210">Paper</a>][<a href="https://youtu.be/q-_wIRq26DY">Demo</a>]<br>
    </li>
	

     <li>
      <b>Deep Feature Pyramid Reconfiguration for Object Detection</b><br>
        Tao Kong, Fuchun Sun, Chuanqi Tan, Huaping Liu, Wenbing Huang<br>
        ECCV 2018. [<a href="https://arxiv.org/abs/1808.07993">Paper</a>][<a href="https://taokong.github.io/papers/eccv2018_kong_poster.pdf">Poster</a>]<br>
    </li>

     <li>
      <b>RON: Reverse Connection with Objectness Prior Networks for Object Detection</b><br>
        Tao Kong, Fuchun Sun, Anbang Yao, Huaping Liu, Yurong Chen, Ming Lu<br>
	CVPR 2017. [<a href="https://arxiv.org/abs/1707.01691">Paper</a>][<a href="https://github.com/taokong/RON">Code</a>]<img alt="GitHub stars" src="https://img.shields.io/github/stars/taokong/RON?label=Stars&style=social"><br>
    </li>
	
    <li>
      <b>HyperNet: Towards Accurate Region Proposal Generation and Joint Object Detection</b><br>
        Tao Kong, Anbang Yao, Yurong Chen, Fuchun Sun<br>
        CVPR 2016, Spotlight. [<a href="https://arxiv.org/abs/1604.00600">Paper</a>] <br>
    </li>

    <li>
        <b>Object Discovery and Grasp Detection with A Shared Convolutional Neural Network</b><br>
        Di Guo, Tao Kong, Fuchun Sun, Huaping Liu<br>
        ICRA 2016, Oral.[<a href="http://ieeexplore.ieee.org/document/7487351/?tp=&arnumber=7487351&url=http:%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D7487351">Paper</a>] <br>
	&#128515;<font color="#800000"><b><a href="https://news.tsinghua.edu.cn/info/1003/23128.htm"><font color="#800000">The 1st place of 2016 IROS Robotic Grasping and Manipulation Competition!</font></a></b></font><br>
    </li>
	
</ul>



		
<h2>Honors & Awards</h2>
<ul> 
    <li>
    <a href="papers/CAAI-Tao.pdf">CAAI Excellent Doctoral Dissertation Nomination Award</a>, 2020
    </li>
    <li>
    CSC Scholarship, 2018
    </li>
    <li>
    The 1st place of IROS Robotic Grasping and Manipulation Competition, 2016
    </li>
    <li>
    Intel Division Recognition Award, 2016
    </li>
    <li>
    Outstanding Graduates in Shandong Province and Shandong University, 2014
    </li>
    <li>
    CCF Outstanding Undergraduate Award, 2013
    </li>
    <li>
    IBM Excellence Scholarship, 2013
    </li>
    <li>
    Young Science Award of Shandong University, 2013
    </li>
    <li>
    National Scholarship, 2012-2013
    </li>
</ul>
	


<!-- <h2>Academic Service</h2>
<ul>    
    <li>
    Conference Reviewer: CVPR, ICCV, ECCV, NeurIPS, ICLR, etc.
    </li>
    <li>
    Journal Reviewer: TPAMI, TIP, PR, etc.
    </li>
</ul> -->

<p></p>
<p align="left"><i>Last update: July, 2021</i> </p>
</body></html>
