<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<!-- saved from url=(0022)http://shijianping.me/ -->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" slick-uniqueid="3"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8">

<meta name="keywords" content="Tao Kong, Kong Tao, Tsinghua, object detection, deep learning, computer vision"> 
<meta name="description" content="Tao Kong&#39;s home page">
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<style type="text/css">
</style>
<title>Tao Kong</title>
<script type="text/javascript" async="" src="ga.js"></script><script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-39824124-1']);
  _gaq.push(['_trackPageview']);

    function show_switch(obj_name) {
        var obj = document.getElementById(obj_name);
        
        if (obj.style.display == "none") {
            obj.style.display = "block";
        }
        else {
            obj.style.display = "none";
        }
    }

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);k
  })();

</script>
</head>
<body>

<div id="layout-content" style="margin-top:25px">

<table>
    <tbody>
        <tr>
			<td width = "350">
				<img src="me.jpg" border="20" width="280">
			</td>
            <td width="670">
                <div id="toptitle">                 
                    <h1>Tao Kong (孔涛)</h1><h1>
                </h1></div>

                <p>      Ph.D. Candidate, Tsinghua University<br>
                                    Haidian District, Beijing, 100084, P.R.China<br>
                    <br>
                    Email: <a href="mailto:taokongcn@gmail.com">taokongcn@gmail.com</a><br>
			   [<a href="https://scholar.google.com/citations?user=kSUXLPkAAAAJ&hl=en">Google Scholar</a>], [<a href="https://github.com/taokong/">Github</a>], [<a href="https://www.zhihu.com/people/kong-tao-72">ZHIHU</a>]
                </p>
            </td>

            <td>&nbsp;</td>
        </tr><tr>
    </tr></tbody>
</table>

  
<h2>Biography</h2>
<p>
    I am now a joint-training Ph.D. student (or called visiting scholar) in the Grasp Laboratory in University of Pennsylvania since Oct 10, 2018, supervised by <a href="http://www.cis.upenn.edu/~jshi">Prof. Jianbo Shi</a>. 
    I am also a 5th-year Ph.D. candidate in <a href="http://www.cs.tsinghua.edu.cn/">Department of Computer Science and Technology</a> in the <a href="http://www.tsinghua.edu.cn">Tsinghua University</a> under the supervision of Prof. Fuchun Sun and Huaping Liu. 
    Before that, I received my bachelor's degree in <a href="http://www.sdu.edu.cn/">Shandong University </a> with honors.
</p>
<p>Previously, I co-founded a promising start-up company, which aimed at machine vision based industry applications and products. I also interned at Visual Computing Group of MSRA and Cognitive Computing Lab of Intel.</p>
<p>My current research focus is on high-level vision, especially for object detection and its relevant topics, such as robot grasp detection, video analysis.</p>
  
<p> </p>
<h2>Selected Publications [<a href="https://scholar.google.com/citations?user=kSUXLPkAAAAJ&hl=en">full</a>]</h2>
  
<ul> 
	<li>
      <a href="https://arxiv.org/abs/1901.06563">Consistent Optimization for Single-Shot Object Detection</a>,<br>
	     <b>Tao Kong</b>, Fuchun Sun, Huaping Liu, Yuning Jiang, Jianbo Shi.<br>
                Tech report, arXiv, 2019<br>
		<font color="red">Bride the training-inference gap of Single-Shot Detector.</font></red><br>
		Improves RetinaNet from 39.1 AP to 40.1 AP on COCO dataset without any bells or whistles!<br>
		[<a href="https://arxiv.org/abs/1901.06563">arXiv</a>][<a href="https://taokong.github.io">code</a>]<br>
        <p></p>
    </li>
	
	<li>
      <a href="https://arxiv.org/abs/1812.01210">Zoom-In-to-Check: Boosting Video Interpolation via Instance-level Discrimination
</a>,<br>
	     Liangzhe Yuan, Yibo Chen, Hantian Liu, <b>Tao Kong</b>, Jianbo Shi.<br>
                Tech report, arXiv, 2018<br>
		[<a href="https://arxiv.org/abs/1812.01210">arXiv</a>][<a href="https://youtu.be/q-_wIRq26DY">demo</a>]<br>
        <p></p>
    </li>
	
     <li>
      <a href="https://arxiv.org/abs/1808.01974">A Survey on Deep Transfer Learning</a>,<br>
	     Chuanqi Tan, Fuchun Sun, <b>Tao Kong</b>, Wenchang Zhang, Chao Yang, Chunfang Liu.<br>
                <em>International Conference on Artificial Neural Networks</em> (<b>ICANN</b>), 2018<br>
		[<a href="https://arxiv.org/abs/1808.01974">arXiv</a>]<br>
        <p></p>
    </li>

     <li>
      <a href="https://arxiv.org/abs/1808.07993">Deep Feature Pyramid Reconfiguration for Object Detection</a>,<br>
        <b>Tao Kong</b>, Fuchun Sun, Chuanqi Tan, Huaping Liu, Wenbing Huang.<br>
                <em>European Conference on Computer Vision</em> (<b>ECCV</b>), 2018<br>
	     	<font color="red">A novel architecture reconguring the feature hierarchy in a flexible yet effective way.</font></red><br>
		[<a href="https://arxiv.org/abs/1808.07993">arXiv</a>][<a href="https://taokong.github.io/papers/eccv2018_kong_poster.pdf">poster</a>]<br>
        <p></p>
    </li>

     <li>
      <a href="https://ieeexplore.ieee.org/abstract/document/7989191">A hybrid deep architecture for robotic grasp detection</a>,<br>
        Di Guo, Fuchun Sun, Huaping Liu, <b>Tao Kong</b>, Bin Fang, Ning Xi.<br>
                <em>IEEE International Conference on Robotics and Automation</em> (<b>ICRA</b>), 2017<br>
        <p></p>
    </li>

     <li>
      <a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Kong_RON_Reverse_Connection_CVPR_2017_paper.pdf">RON: Reverse Connection with Objectness Prior Networks for Object Detection</a>,<br>
        <b>Tao Kong</b>, Fuchun Sun, Anbang Yao, Huaping Liu, Yurong Chen, Ming Lu.<br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2017<br>
	     	<font color="red">27.4 mAP on COCO dataset with VGG 16 backbone.</font></red><br>
		We won the <font color="red"><b>1st place</b></font></red> of  <a href="http://www.rhgm.org/activities/competition_iros2016/"> 2016 IROS Robotic Grasping and Manipulation Competition</a>!</font></red><br>
	     	[<a href="https://github.com/taokong/RON">code</a>][<a href="https://taokong.github.io/papers/RON_introduction.pdf">slides</a>][<a href="https://taokong.github.io/papers/ron_cvpr17_poster.pdf">poster</a>][<a href="https://youtu.be/VKZMmHx36SE">demo</a>]<br>
        <p></p>
    </li>

    <li>
      <a href="https://journals.sagepub.com/doi/pdf/10.1177/1729881416682706">Deep vision networks for real-time robotic grasp detection</a>,<br>
	    Di Guo, Fuchun Sun, <b>Tao Kong</b>, Huaping Liu .<br>
                <em>International Journal of Advanced Robotic Systems</em> (<b>IJARS</b>), 2016<br>
        <p></p>
    </li>
	
    <li>
      <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Kong_HyperNet_Towards_Accurate_CVPR_2016_paper.pdf">HyperNet: Towards Accurate Region Proposal Generation and Joint Object Detection</a>,<br>
        <b>Tao Kong</b>, Anbang Yao, Yurong Chen, Fuchun Sun .<br>
                <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<b>CVPR</b>), 2016 (<em>spotlight presentation</em>) <br>
	    	<font color="red">Top-2 on VOC2007&2012 dataset(Oct, 2015), 42.0 AP on MS COCO 2017</font></red>
        <p></p>
    </li>

    <li>
      <a href="http://ieeexplore.ieee.org/document/7487351/?tp=&arnumber=7487351&url=http:%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D7487351">
      Object discovery and grasp detection with a shared convolutional neural network,<br></a>
        Di Guo, <b>Tao Kong</b>, Fuchun Sun, Huaping Liu.<br>
            <em> IEEE International Conference on Robotics and Automation</em> (<b>ICRA</b>), 2016, (<em>oral presentation</em>)  <br>
	    <font color="red">100 fps on a real robotic platform to discover&grasp a target object from the stack!</font></red> 
        <p></p>
    </li>

    <li>
      <a href="http://link.springer.com/article/10.1186/1687-6180-2014-44">
      A hierarchical classification method for finger knuckle print recognition,<br></a>
        <b>Tao Kong</b>, Gongping Yang, Lu Yang.<br>
            <em> EURASIP Journal on Advances in Signal Processing</em>, 2014, doi: <em>10.1186/1687-6180-2014-44</em><br>
        <p></p>

    </li>

    <li>
      <a href="http://link.springer.com/article/10.1007/s13042-013-0208-y">
      A new finger-knuckle-print ROI extraction method based on probabilistic region growing algorithm,<br></a>
        <b>Tao Kong</b>, Gongping Yang, Lu Yang.<br>
            <em> International Journal of Machine Learning and Cybernetics</em>, 2014, doi: <em>10.1007/s13042-013-0208-y</em><br>
        <p></p>

    </li>


</ul>
<p> </p>
  
<h2>Awards and Honor</h2>
<ul>    
    <li>
    The <b>1st place</b> of  <a href="http://www.rhgm.org/activities/competition_iros2016/"> 2016 IROS Robotic Grasping and Manipulation Competition</a>, 2016 
    </li>
    <li>
     Division Recognition Award (DRA): Excellence in Speed & Execution, ILC, 2016
    </li>
    <li>
    The <b>1st Price</b> of CUMCM(China Undergraduate Mathematical Contest in Modeling), 2014
    </li>
    <li>
    Outstanding Graduates of Shandong Province, 2014
    </li>
    <li>
    The CCF Outstanding Undergraduate, 2014
    </li>
    <li>
    National Undergraduate Scholarship, 2012-2013
    </li>
</ul>

<h2> Professional Activities</h2>
<ul>    
    <li>
    Conference Reviewer: CVPR(2017/2018/2019), ECCV2018, 
    </li>
    <li>
    PC Member: IJCAI-ECAI2018/IJCAI2019, IROS(2018), AAAI(2019).
    </li>
    <li>
    Journal Reviewer: TIP(from 2018).
    </li>
</ul>

<h2> Useful Links and Resourses</h2>
<ul>   
    <li>
    <a href="https://taokong.github.io/report/DCN_v2_paper_reading.pdf">"Deformable ConvNets v2 group reading "</a> at UPenn.
    </li>
    <li>
    Talk on <a href="https://taokong.github.io/report/course2017.pdf">"Detecting objects with deep learning hammer"</a> at Tsinghua.
    </li>
</ul>   

<p>　</p>
<p>　</p>
<a href="http://www.easycounter.com/">
<img src="//www.easycounter.com/counter.php?taokongcn"
border="0" alt="Free Hit Counters"></a>
<br><a href="http://www.easycounter.com/">visitors
        since May 2016</a>

<p align="left"><i>Last update: January, 2019</i> </p>


</body></html>
