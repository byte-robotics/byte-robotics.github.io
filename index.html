<html><head>
<title>Tao Kong</title>

<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">

<script src="https://code.jquery.com/jquery-3.1.1.slim.min.js" integrity="sha384-A7FZj7v+d/sdmMqp/nOQwliLvUsJfDHW+k9Omg/a/EheAdgtzNs3hpfag6Ed950n" crossorigin="anonymous"></script>

<style type="text/css">
 @import url("http://fonts.googleapis.com/css?family=Source+Sans+Pro:300,300italic,600,600italic");


	body
	{
	font-family:"Roboto",Helvetica,Arial,sans-serif;font-size:16px;line-height:1.5;font-weight:300;
    	background-color : #CDCDCD;
	}
    	.content
	{
    		width : 900px;
    		padding : 25px 30px;
    		margin : 25px auto;
    		background-color : #fff;
    		box-shadow: 0px 0px 10px #999;
    		border-radius: 15px; 
	}	
	table
	{
		padding: 5px;
	}
	
	table.pub_table,td.pub_td1,td.pub_td2
	{
		padding: 8px;
		width: 850px;
        border-collapse: separate;
        border-spacing: 15px;
        margin-top: -5px;
	}

	td.pub_td1
	{
		width:50px;
	}
    td.pub_td1 img
    {
        height:120px;
        width: 160px;
    }
	
	div#container
	{
		margin-left: auto;
		margin-right: auto;
		width: 820px;
		text-align: left;
		position: relative;
		background-color: #FFF;
	}
	div#DocInfo
	{
		color: #1367a7;
		height: 158px;
		margin-left: 20px;
	}
	h4,h3,h2,h1
	{
		color: #3B3B3B;
	}
	h2
	{
		font-size:130%;
	}
	p
	{
		color: #5B5B5B;
		margin-bottom: 50px;
	}
	p.caption
	{
		color: #9B9B9B;
		text-align: left;
		width: 600px;
	}
	p.caption2
	{
		color: #9B9B9B;
		text-align: left;
		width: 800px;
	}
	#header_img
	{
		position: absolute;
		top: 0px; right: 0px;
    }
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}

    #mit_logo {
        position: absolute;
        left: 646px;
        top: 14px;
        width: 200px;
        height: 20px;
    }
   
    table.pub_table tr {
        outline: thin dotted #666666;
    }
    .papericon {
        border-radius: 8px; 
        -moz-box-shadow: 3px 3px 6px #888;
        -webkit-box-shadow: 3px 3px 6px #888;
        box-shadow: 3px 3px 6px #888;
        width: 180px;
	margin-top:5px;
	margin-left:5px;
	margin-bottom:5px;
    }

     .papericon_blank {

        width: 160px;
	margin-top:5px;
	margin-left:5px;
	margin-bottom:5px;
    }

    .media {
	outline: thin dotted #666666;
 	margin-bottom: 15px;	
	margin-left:10px;
    }
    .media-body {
	margin-top:5px;
	padding-left:20px;
    }
    .instructorphoto img {
	  width: 170px;
	  border-radius: 170px;
	  margin-bottom: 10px;
	}


.papers-selected h5, .papers-selected h4 { display : none; }
.papers-selected .publication { display : none; }
.paperhi-only { display : none; }
.papers-selected .paperhi { display : flex; }
.papers-selected .paperlo { display : none; }

.hidden>div {
	display:none;
}

.visible>div {
	display:block;
}
</style>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-23931362-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-23931362-2');
</script>

<script type="text/javascript">
    var myPix = new Array("profile.jpg")
    function choosePic() {
        var randomNum = Math.floor(Math.random() * myPix.length);
        document.getElementById("myPicture").src = myPix[randomNum];
    };
</script>

<script>
$(document).ready(function() {
  $('.paperlo button').click(function() {
     $('.papers-container').addClass('papers-selected');
  });
  $('.paperhi button').click(function() {
     $('.papers-container').removeClass('papers-selected');
  });


	$('.text_container').addClass("hidden");

	$('.text_container').click(function() {
		var $this = $(this);

		if ($this.hasClass("hidden")) {
			$(this).removeClass("hidden").addClass("visible");
			$(this).removeClass("papericon");
		} else {
			$(this).removeClass("visible").addClass("hidden");
		}
	});


});
</script>

</head>

<body>
<div class="content">
	<div id="container">

	<table>
	<tbody><tr>
	<td><div class="instructorphoto"><img id="myPicture" src="profile.jpg" style="float:left;"></div></td>
	<script>choosePic();</script>
	<td>
	<div id="DocInfo">
		<h1>Tao Kong</h1><br>
        ByteDance AI Lab<br><br>
        Email: <a href="mailto:taokongcn@gmail.com">taokongcn@gmail.com</a><br><br>
        <a href="https://scholar.google.com/citations?user=kSUXLPkAAAAJ&hl=en">Google Scholar</a> &bull; 
		<a href="https://arxiv.org/find/cs/1/au:+Kong_Tao/0/1/0/all/0/1">arXiv</a> &bull; 
		<a href="https://github.com/taokong">Github</a> &bull; 
		<a href="https://www.zhihu.com/people/kong-tao-72">Zhihu</a><br>
	</div><br>
    <!--
    <div id="mit_logo">
        <a href="http://www.mit.edu"><img src="image/mit.gif" height="170px" class="papericon" /></a>
    </div>
    -->
	</td>
	</tr>
	</tbody></table>
	<br>
	

<h2>Intro</h2>
<ul>
<li>Tao Kong is currently a research scientist at Bytedance AI Lab.</li>
<li>He received Ph.D. degree at Tsinghua University under the supervision of Prof. Fuchun Sun. 
    From Oct 2018 to Mar 2019, he visited Grasp Lab in University of Pennsylvania, working with Prof. Jianbo Shi. </li>
<li>Previously, he interned at VC Group of MSRA and Cognitive Computing Lab of Intel.</li>
<li>We are recruiting self-motivated interns / full-time researchers and developers in vision / language understanding, 
	and robotics learning. If you are interested, please drop me an email. </li>
</ul> 
	

<h2>News</h2>	
    <ul>
	<li>[03/2021] For papers are accepted to CVPR 2021, and DenceCL is selected as the Oral presentation! </li>    
	<li>[01/2021] Organizing a tutorial <a href="https://www.2021.ieeeicip.org">Recent Progress on Visual Object Detection and Segmentation</a> at ICIP 2021. </li>    
        <li>[09/2020] My thesis is nominated as CAAI Excellent Doctoral Dissertation Award. </li>    
	<li>[09/2020] Our <a href="https://arxiv.org/abs/1912.04488">SOLOv2</a> work is accepted to NeurIPS 2020. </li>    
        <li>[07/2020] Our <a href="https://arxiv.org/abs/1912.04488">SOLO</a> work is accepted to ECCV 2020. </li>
        <li>[06/2020] Our <a href="https://arxiv.org/abs/1904.03797">FoveaBox</a> work is accepted to TIP 2020. </li>

    </ul>

	
<h2>Selected Publications <small><small>(*Interns or Students, <sup>+</sup> Equal contribution)</small></small></h2>
<ul> 
      <li>
      <a href="http://www.taokong.org">Scale-aware Automatic Augmentation for Object Detection</a><br>
	     Yukang Chen*, Yanwei Li*, <b>Tao Kong</b>, Lu Qi*, Ruihang Chu*, Lei Li and Jiaya Jia<br>
             CVPR 2021. [<a href="https://arxiv.org">arXiv</a>]<br>
      </li>
	
      <li>
      <a href="http://www.taokong.org">Locate then Segment: A Strong Pipeline for Referring Image Segmentation</a><br>
	     Ya Jing*, <b>Tao Kong</b>, Wei Wang, Liang Wang, Lei Li and Tieniu Tan<br>
             CVPR 2021. [<a href="https://arxiv.org">arXiv</a>]<br>
      </li>
	
      <li>
      <a href="https://arxiv.org/abs/2011.09157">Dense Contrastive Learning for Self-Supervised Visual Pre-Training</a><br>
	     Xinlong Wang*, Rufeng Zhang*, Chunhua Shen, <b>Tao Kong</b> and Lei Li<br>
             CVPR 2021, Oral. [<a href="https://arxiv.org/abs/2011.09157">arXiv</a>][<a href="https://github.com/WXinlong/DenseCL">Code@Github</a>]<img alt="GitHub stars" src="https://img.shields.io/github/stars/WXinlong/DenseCL?label=Stars&style=social"><br>
      </li>
	
      <a href="https://arxiv.org/abs/2011.12450">Sparse R-CNN: End-to-End Object Detection with Learnable Proposals</a><br>
	Peize Sun*, Rufeng Zhang*, Yi Jiang,  <b>Tao Kong</b>, Chenfeng Xu, Wei Zhan, Masayoshi Tomizuka, Lei Li, Zehuan Yuan, Changhu Wang, Ping Luo<br>
             CVPR 2021. [<a href="https://arxiv.org/abs/2011.12450">arXiv</a>][<a href="https://github.com/PeizeSun/SparseR-CNN">Code@Github</a>]<img alt="GitHub stars" src="https://img.shields.io/github/stars/PeizeSun/SparseR-CNN?label=Stars&style=social"><br>
      </li>
	
	
      <li>
      <a href="https://arxiv.org/abs/2003.10152">SOLOv2: Dynamic and Fast Instance Segmentation</a><br>
	     Xinlong Wang*, Rufeng Zhang*, <b>Tao Kong</b>, Lei Li and Chunhua Shen<br>
             NeurIPS 2020. [<a href="https://arxiv.org/abs/2003.10152">arXiv</a>][<a href="https://github.com/WXinlong/SOLO">Code@Github</a>]<img alt="GitHub stars" src="https://img.shields.io/github/stars/WXinlong/SOLO?label=Stars&style=social"><br>
      </li>

      <li>
      <a href="https://arxiv.org/abs/1912.04488">SOLO: Segmenting Objects by Locations</a><br>
	     Xinlong Wang*, <b>Tao Kong</b>, Chunhua Shen, Yuning Jiang and Lei Li<br>
             ECCV 2020. [<a href="https://arxiv.org/abs/1912.04488">arXiv</a>][<a href="https://github.com/WXinlong/SOLO">Code@Github</a>]<img alt="GitHub stars" src="https://img.shields.io/github/stars/WXinlong/SOLO?label=Stars&style=social"><br>
      </li>
	
      <li>
      <a href="https://arxiv.org/abs/1904.03797">FoveaBox: Beyond Anchor-based Object Detector</a><br>
	     <b>Tao Kong</b>, Fuchun Sun, Huaping Liu, Yuning Jiang, Lei Li, Jianbo Shi<br>
             TIP 2020. [<a href="https://arxiv.org/abs/1904.03797">arXiv</a>][<a href="https://github.com/open-mmlab/mmdetection/tree/master/configs/foveabox">Code@mmdet</a>][<a href="https://github.com/taokong/FoveaBox">Code@Github</a>]<img alt="GitHub stars" src="https://img.shields.io/github/stars/taokong/FoveaBox?label=Stars&style=social"><br>
      </li>
	      
      <li>
      <a href="https://arxiv.org/abs/1909.07701">Task-Aware Monocular Depth Estimation for 3D Object Detection
</a><br>
	     Xinlong Wang*, Wei Yin*, <b>Tao Kong</b>, Yuning Jiang, Lei Li and Chunhua Shen<br>
             AAAI 2020, Oral. [<a href="https://arxiv.org/abs/1909.07701">arXiv</a>][<a href="https://github.com/WXinlong/ForeSeE">Code@Github</a>]<img alt="GitHub stars" src="https://img.shields.io/github/stars/WXinlong/ForeSeE?label=Stars&style=social"><br>
      </li>
 
	
    <li>
      <a href="https://ieeexplore.ieee.org/document/8721661/authors#authors">Feature Pyramid Reconfiguration with Consistent Loss for Object Detection
</a>,<br>
	     <b>Tao Kong</b><sup>+</sup>, Fuchun Sun<sup>+</sup>,  Wenbing Huang, Chuanqi Tan, Bin Fang, Huaping Liu<br>
             TIP 2019.<br>
    </li>
	
	<li>
      <a href="https://arxiv.org/abs/1812.01210">Zoom-In-to-Check: Boosting Video Interpolation via Instance-level Discrimination
</a><br>
	     Liangzhe Yuan*, Yibo Chen*, Hantian Liu*, <b>Tao Kong</b>, Jianbo Shi<br>
             CVPR 2019. [<a href="https://arxiv.org/abs/1812.01210">arXiv</a>][<a href="https://youtu.be/q-_wIRq26DY">demo</a>]<br>
    </li>
	

     <li>
      <a href="https://arxiv.org/abs/1808.07993">Deep Feature Pyramid Reconfiguration for Object Detection</a><br>
        <b>Tao Kong</b>, Fuchun Sun, Chuanqi Tan, Huaping Liu, Wenbing Huang<br>
        ECCV 2018. [<a href="https://arxiv.org/abs/1808.07993">arXiv</a>][<a href="https://taokong.github.io/papers/eccv2018_kong_poster.pdf">poster</a>]<br>
    </li>

     <li>
      <a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Kong_RON_Reverse_Connection_CVPR_2017_paper.pdf">RON: Reverse Connection with Objectness Prior Networks for Object Detection</a><br>
        <b>Tao Kong</b>, Fuchun Sun, Anbang Yao, Huaping Liu, Yurong Chen, Ming Lu<br>
	CVPR 2017. [<a href="https://arxiv.org/abs/1707.01691">arXiv</a>][<a href="https://github.com/taokong/RON">Code@Github</a>]<img alt="GitHub stars" src="https://img.shields.io/github/stars/taokong/RON?label=Stars&style=social"><br>
    </li>
	
    <li>
      <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Kong_HyperNet_Towards_Accurate_CVPR_2016_paper.pdf">HyperNet: Towards Accurate Region Proposal Generation and Joint Object Detection</a><br>
        <b>Tao Kong</b>, Anbang Yao, Yurong Chen, Fuchun Sun<br>
        CVPR 2016, Spotlight. <br>
    </li>

    <li>
      <a href="http://ieeexplore.ieee.org/document/7487351/?tp=&arnumber=7487351&url=http:%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D7487351">
      Object Discovery and Grasp Detection with A Shared Convolutional Neural Network<br></a>
        Di Guo, <b>Tao Kong</b>, Fuchun Sun, Huaping Liu<br>
        ICRA 2016, Oral.<br>
	<a href="https://news.tsinghua.edu.cn/info/1003/23128.htm">The 1st place of 2016 IROS Robotic Grasping and Manipulation Competition!</a><br>
    </li>

	
</ul> 

<h2>Honors & Awards</h2>
<ul> 
    <li>
    <a href="papers/CAAI-Tao.pdf">CAAI Excellent Doctoral Dissertation Nomination Award</a>, 2020
    </li>
    <li>
    CSC Scholarship, 2018
    </li>
    <li>
    The 1st place of IROS Robotic Grasping and Manipulation Competition, 2016
    </li>
    <li>
    Intel Division Recognition Award, 2016
    </li>
    <li>
    Outstanding Graduates in Shandong Province and Shandong University, 2014
    </li>
    <li>
    CCF Outstanding Undergraduate Award, 2013
    </li>
    <li>
    IBM Excellence Scholarship, 2013
    </li>
    <li>
    Young Science Award of Shandong University, 2013
    </li>
    <li>
    National Scholarship, 2012-2013
    </li>
</ul>
	


<!-- <h2>Academic Service</h2>
<ul>    
    <li>
    Conference Reviewer: CVPR, ICCV, ECCV, NeurIPS, ICLR, etc.
    </li>
    <li>
    Journal Reviewer: TPAMI, TIP, PR, etc.
    </li>
</ul> -->


<a href="http://www.easycounter.com/">
<img src="//www.easycounter.com/counter.php?taokongcn"
border="0" alt="Free Hit Counters"></a>
<br><a href="http://www.easycounter.com/">visitors
        since May 2016</a>

<p align="left"><i>Last update: Mar, 2021</i> </p>


</body></html>
